Okay, we have the necessary planning documents (`PLAN_AST_BLUEPRINT.MD`, `PLAN_AST_ROADMAP.MD`, `PLAN_AST_TDD.MD`, and `PLAN_AST_CONCERNS.MD`). We are now ready to start generating the content for `docs/ast/PROMPTS_GEMINI.md`.

This will be a very large document, so I will generate it in sections, starting with the Introduction and then proceeding phase by phase, component by component, as outlined in the plan.

```markdown
# docs/ast/PROMPTS_GEMINI.md - Staged Test-Driven Prompts for ElixirScope AST Layer

**Version:** 1.0
**Date:** [Current Date]
**Objective:** This document provides a comprehensive, staged, and test-driven prompting strategy for Gemini to implement the ElixirScope AST Layer (Layer 2). It synthesizes requirements and design details from all `docs/ast/*.md` files, `DEV.md`, Foundation layer documentation, and the preliminary planning documents:
    - `PLAN_AST_BLUEPRINT.md`
    - `PLAN_AST_ROADMAP.md`
    - `PLAN_AST_TDD.md`
    - `PLAN_AST_CONCERNS.md`

## Introduction

The ElixirScope AST Layer will be developed incrementally using a **Test-Driven Development (TDD)** approach. For each component and feature, prompts will first guide the generation of tests (unit, integration, contract), followed by prompts for the implementation code required to make those tests pass.

This strategy ensures:
1.  **Clarity of Requirements:** Tests define the expected behavior before implementation.
2.  **Incremental Verification:** Each piece of code is verified as it's developed.
3.  **Layer Stability:** Each stage produces a compilable, testable, and functionally stable increment.
4.  **Contract Adherence:** Strict compliance with defined API contracts (internal and with the Foundation Layer).
5.  **Comprehensive Coverage:** Prompts will cover all aspects defined in the planning and design documents.

**General Instructions for Gemini:**
*   Unless otherwise specified, assume Elixir 1.15+ syntax and OTP best practices.
*   Adhere strictly to naming conventions, directory structures, and OTP patterns defined in `DEV.md` and `docs/ast/SUPERVISION_TREE.md`.
*   All public functions should have `@doc` and `@spec` annotations.
*   Error handling should conform to `docs/ast/AST_FOUNDATION_API_ENHANCED.md` Section 4, primarily returning `{:ok, value} | {:error, %ElixirScope.Foundation.Error{}}`.
*   Logging should be incorporated as per `docs/ast/PLAN_AST_CONCERNS.md` Section 3.
*   Pay close attention to the **Success Metrics** provided with each prompt group, as these define the acceptance criteria for your generated output.

---

## Phase 1: Core Repository & Data Structures

**Goal:** Establish the foundational data storage (ETS tables) and core data models (`ModuleData`, `FunctionData`) for the AST layer.
**Relevant Documents:** `docs/ast/REQ-01-CORE-REPOSITORY.md`, `docs/ast/EST_SCHEMA.md`, `docs/ast/AST_PRD.md` (Sections 2.1, 3.1), `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` (Sections 1.1, 5.1, 5.2), `PLAN_AST_BLUEPRINT.md`, `PLAN_AST_TDD.md` (Phase 1), `PLAN_AST_CONCERNS.md`.

---

### Component: `ElixirScope.AST.Data.ModuleData`

**File:** `lib/elixir_scope/ast/data/module_data.ex`
**Role:** Struct/Module defining the data representation for an Elixir module.
**References:**
    - Blueprint: `PLAN_AST_BLUEPRINT.md` (Data Structures section)
    - PRD: `docs/ast/AST_PRD.md` (Section 3.1.1)
    - Interfaces: `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` (Section 5.1)
    - TDD Plan: `PLAN_AST_TDD.md` (Phase 1 - ModuleDataTest)
    - Concerns: `PLAN_AST_CONCERNS.md` (Error Handling)

#### Prompt 1.1.1: Test Generation for `ModuleData`

**Instruction to Gemini:**

"Generate the ExUnit test file `test/unit/elixir_scope/ast/data/module_data_test.exs` for the module `ElixirScope.AST.Data.ModuleData`.
The test module should be named `ElixirScope.AST.Data.ModuleDataTest` and use `use ExUnit.Case, async: true`.

Focus on testing the `ElixirScope.AST.Data.ModuleData.new/3` function and the `ElixirScope.AST.Data.ModuleData.validate/1` function (assume it will be created).

**For `new/3` (`(module_name :: atom(), ast :: Macro.t(), opts :: keyword()) :: ModuleData.t() | {:error, Error.t()}`):**
1.  **Scenario: Valid Creation:**
    *   **Arrange:** A valid atom for `module_name` (e.g., `MyApp.TestModule`), a simple valid Elixir AST (e.g., `quote do def hello, do: "world" end`), and `opts` including `source_file: "path/to/file.ex"`.
    *   **Act:** Call `ModuleData.new/3`.
    *   **Assert:**
        *   The result is a `%ElixirScope.AST.Data.ModuleData{}` struct.
        *   Fields like `module_name`, `ast`, `source_file` are correctly populated.
        *   `compilation_hash` is a binary string (simple hash for now, e.g., from `inspect(ast)`).
        *   `created_at` and `updated_at` are recent `DateTime.t()` structs and are equal.
        *   Other fields from `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` Section 5.1 (e.g., `instrumentation_points`, `correlation_metadata`, `complexity_metrics`, `dependencies`, `exports`, `callbacks`, `patterns`, `attributes`) are initialized to sensible defaults (e.g., empty lists or maps).
        *   `version` field is set to "2.0.0" (as per `AST_MIGRATION_IMPLEMENTATION_CURSOR_GUIDE.md` example).
2.  **Scenario: Creation with `MIGRATION_INTEGRATION_CO_PRD.md` context:**
    *   The `new/3` function in `AST_MIGRATION_IMPLEMENTATION_CURSOR_GUIDE.md` shows a `new/3` that can return `{:ok, t()} | {:error, Error.t()}` and uses `Foundation.Config`, `Foundation.Error`, `Foundation.Telemetry`. For this initial test, assume `new/3` returns `ModuleData.t()` directly on success and raises an error or returns a simple `{:error, reason}` on failure if Foundation integration is not yet prompted. If prompting for the full `AST_MIGRATION_IMPLEMENTATION_CURSOR_GUIDE.md` version, then test for `{:ok, t()}`.
    *   (If prompting for the simpler version first): Add a TODO comment to update this test when `new/3` is enhanced to use Foundation services and return `{:ok, t()} | {:error, Error.t()}`.

**For `validate/1` (`(module_data :: ModuleData.t()) :: :ok | {:error, Error.t()}`):**
1.  **Scenario: Valid `ModuleData`:**
    *   **Arrange:** A `ModuleData.t()` struct created via a successful `new/3` call.
    *   **Act:** Call `ModuleData.validate/1`.
    *   **Assert:** The result is `:ok`.
2.  **Scenario: Invalid `ModuleData` - `module_name` not an atom:**
    *   **Arrange:** A `ModuleData.t()` struct where `module_name` is manually set to a string.
    *   **Act:** Call `ModuleData.validate/1`.
    *   **Assert:** The result is `{:error, %ElixirScope.Foundation.Error{type: :validation_failed}}` (or a similar AST-specific error type if defined, otherwise use a generic validation error).
3.  **Scenario: Invalid `ModuleData` - `ast` is not a valid AST:**
    *   **Arrange:** A `ModuleData.t()` struct where `ast` is manually set to `nil` or an integer.
    *   **Act:** Call `ModuleData.validate/1`.
    *   **Assert:** The result is `{:error, %ElixirScope.Foundation.Error{type: :validation_failed}}`.

Include `@moduledoc false` and necessary aliases (`ElixirScope.AST.Data.ModuleData`, `ElixirScope.Foundation.Error`).
"

**Success Metrics for Prompt 1.1.1:**
*   Test file `test/unit/elixir_scope/ast/data/module_data_test.exs` is generated.
*   The test module compiles.
*   Tests cover the specified scenarios for `new/3` and `validate/1`.
*   Assertions are clear and check the described conditions.

---

#### Prompt 1.1.2: `ModuleData` Struct and Basic `new/3` Implementation

**Instruction to Gemini:**

"Generate the module `ElixirScope.AST.Data.ModuleData` in `lib/elixir_scope/ast/data/module_data.ex`.

1.  **Module Definition:**
    *   Define the module with `@moduledoc` explaining its purpose (refer to `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` Section 5.1).
2.  **Struct Definition:**
    *   Define the `defstruct` for `ElixirScope.AST.Data.ModuleData`. Include all fields as specified in `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` Section 5.1 (`module_name`, `ast`, `source_file`, `compilation_hash`, `instrumentation_points`, `ast_node_mapping`, `correlation_metadata`, `module_type`, `complexity_metrics`, `dependencies`, `exports`, `callbacks`, `patterns`, `attributes`, `runtime_insights`, `execution_frequency`, `performance_data`, `error_patterns`, `message_flows`, `created_at`, `updated_at`). Add a `version` field.
    *   Initialize fields to sensible defaults (e.g., `nil`, empty lists `[]`, empty maps `%{}`).
3.  **Type Specification:**
    *   Define `@type t :: %__MODULE__{...}` with all fields and their expected types. Refer to `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` Section 5.1 for guidance on types (e.g., `module_name :: atom()`, `ast :: Macro.t()`, `instrumentation_points :: [map()]`, `created_at :: DateTime.t()`).
4.  **`new/3` Function:**
    *   Implement the `new(module_name :: atom(), ast :: Macro.t(), opts :: keyword()) :: t()` function.
    *   It should populate the struct fields based on the input arguments and `opts`.
    *   `source_file` should be taken from `Keyword.get(opts, :source_file)`.
    *   `compilation_hash`: For now, generate a simple SHA256 hash of `inspect(ast) <> source_file`. Use `:crypto.hash(:sha256, content) |> Base.encode16(case: :lower)`.
    *   `created_at` and `updated_at`: Set to `DateTime.utc_now()`.
    *   `version`: Set to `"2.0.0"`.
    *   Initialize other analytical fields (like `dependencies`, `patterns`, etc.) to empty lists or maps as per their types.
    *   For now, this function should return the `ModuleData.t()` struct directly on success. Error handling and Foundation integration will be added in a subsequent prompt.
    *   Add `@doc` and `@spec`.

Include necessary aliases like `DateTime`.
"

**Success Metrics for Prompt 1.1.2:**
*   Module `ElixirScope.AST.Data.ModuleData` is generated in the correct file.
*   The `defstruct` includes all specified fields with appropriate defaults.
*   The `@type t` specification is complete and accurate.
*   The `new/3` function is implemented as described, correctly populating fields and returning the struct.
*   The module compiles without warnings.
*   The previously generated tests for `new/3` (valid creation scenario) should now pass or be very close to passing.

---

#### Prompt 1.1.3: `ModuleData.validate/1` Implementation

**Instruction to Gemini:**

"In the `ElixirScope.AST.Data.ModuleData` module:

Implement the function `validate(module_data :: t()) :: :ok | {:error, ElixirScope.Foundation.Error.t()}`.

1.  **Validation Logic:**
    *   Check if `module_data.module_name` is an atom. If not, return `{:error, %ElixirScope.Foundation.Error{code: <AST_VALIDATION_CODE_1>, type: :validation_failed, message: "Module name must be an atom", context: %{field: :module_name, value: module_data.module_name}}}`.
    *   Check if `module_data.ast` is a valid Elixir AST (e.g., a tuple or a list of tuples representing quoted code). A simple check for now could be `is_tuple(module_data.ast) or (is_list(module_data.ast) and Enum.all?(module_data.ast, &is_tuple/1))`. If not, return `{:error, %ElixirScope.Foundation.Error{code: <AST_VALIDATION_CODE_2>, type: :validation_failed, message: "Invalid AST structure", context: %{field: :ast}}}`.
    *   Check if `module_data.source_file` is a binary/string.
    *   Check if `module_data.created_at` and `module_data.updated_at` are `DateTime.t` structs.
    *   If all checks pass, return `:ok`.
    *   Use appropriate error codes (e.g., starting from 2000 for AST validation errors, choose unique ones like 2001, 2002). Set severity, category (`:ast`), and subcategory (`:validation`).
2.  Add `@doc` and `@spec`.

Make sure to alias `ElixirScope.Foundation.Error`.
"

**Success Metrics for Prompt 1.1.3:**
*   The `validate/1` function is implemented in `ElixirScope.AST.Data.ModuleData`.
*   It performs the specified validations.
*   Returns `:ok` for valid data and `{:error, %ElixirScope.Foundation.Error{}}` with correct details for invalid data.
*   The module compiles.
*   The previously generated tests for `validate/1` should now pass.

---
**(This pattern would continue for `FunctionData`, then `Repository.Core` Supervisor and GenServer, including their tests first, then basic structure, then function implementations one by one or in small logical groups, always referencing the planning documents and specific interface/requirement documents.)**

---

### Component: `ElixirScope.AST.Repository.Core`

**File:** `lib/elixir_scope/ast/repository/core.ex`
**Role:** GenServer managing ETS-based storage for AST data.
**References:**
    - Blueprint: `PLAN_AST_BLUEPRINT.md`
    - REQ-01: `docs/ast/REQ-01-CORE-REPOSITORY.md`
    - ETS Schema: `docs/ast/EST_SCHEMA.md` (Sections 2, 3, 5.1)
    - Interfaces: `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` (Section 1.1)
    - Supervision: `docs/ast/SUPERVISION_TREE.md`
    - TDD Plan: `PLAN_AST_TDD.md` (Phase 1 - CoreTest, CoreHealthTest, CoreStorageTest)
    - Concerns: `PLAN_AST_CONCERNS.md` (OTP, Error Handling, Logging, Foundation Health/Telemetry stubs)
    - Foundation API: `docs/ast/AST_FOUNDATION_API_ENHANCED.md` (Error types, HealthCheckable)

#### Prompt 1.2.1: Test Generation for `Repository.Core` Lifecycle and Basic CRUD

**Instruction to Gemini:**

"Generate the ExUnit test file `test/unit/elixir_scope/ast/repository/core_test.exs` for `ElixirScope.AST.Repository.Core`.
Name the test module `ElixirScope.AST.Repository.CoreTest` and use `use ExUnit.Case, async: false` (due to GenServer and ETS state).

**Include tests for:**
1.  **GenServer Lifecycle:**
    *   `start_link/1`:
        *   Scenario: Successful start. Assert: `{:ok, pid}` is returned, GenServer is alive, and ETS tables (`:ast_modules`, `:ast_functions`, `:ast_nodes`, `:correlation_index` as per `EST_SCHEMA.md`) are created with specified options (e.g., `:set`, `:public`, `read_concurrency: true`).
        *   Mock `Foundation.Config.get/2` to return default ETS options if `Repository.Core` reads them during `init/1`.
    *   `terminate/2`: (This is harder to test directly without internal state inspection or specific side effects like logging. For now, ensure `stop/1` works if you implement a public API for it, or focus on ETS table cleanup if possible to observe).
2.  **Module Operations (using `GenServer.call/3`):**
    *   `store_module/2` (`handle_call({:store_module, module_data}, ...)`):
        *   Scenario: Store a valid `ModuleData.t()`. Assert: `{:ok, :stored}` (or agreed success atom), data exists in `:ast_modules` ETS table.
        *   Scenario: Attempt to store non-ModuleData. Assert: `{:error, %Foundation.Error{type: :validation_failed}}`.
    *   `get_module/2` (`handle_call({:get_module, module_name}, ...)`):
        *   Scenario: Get an existing module. Assert: `{:ok, %ModuleData{}}` with correct data.
        *   Scenario: Get a non-existent module. Assert: `{:error, %Foundation.Error{type: :not_found}}`.
    *   (Stub tests for `update_module/3`, `delete_module/2`, `list_modules/1` - to be detailed later).
3.  **Function Operations (similar structure to Module Operations, using `:ast_functions` table):**
    *   `store_function/2`, `get_function/2`.
4.  **AST Node Operations (similar, using `:ast_nodes` table):**
    *   `store_ast_node/3`, `get_ast_node/2`.
5.  **Correlation Operations (similar, using `:correlation_index` table):**
    *   `correlate_event/3`, `get_correlation/2`.
6.  **Basic Statistics & Health (stubs for now):**
    *   `get_statistics/0` (`handle_call(:get_statistics, ...)`): Assert: `{:ok, map_with_basic_counts}` (e.g., module_count: 0 initially).
    *   `health_check/0` (`handle_call(:health_check, ...)`): Assert: `{:ok, %{status: :healthy, details: map()}}`. This will also be covered by a contract test.

Use a `setup` block to start the `Repository.Core` GenServer for each test using `start_supervised!({ElixirScope.AST.Repository.Core, name: TestRepo})`. Ensure ETS tables are cleaned up or the GenServer is stopped `on_exit` to maintain test isolation.

Alias necessary modules: `ElixirScope.AST.Repository.Core`, `ElixirScope.AST.Data.ModuleData`, `ElixirScope.Foundation.Error`.
"

**Success Metrics for Prompt 1.2.1:**
*   Test file `test/unit/elixir_scope/ast/repository/core_test.exs` is generated.
*   Test module compiles.
*   Tests cover the specified GenServer lifecycle and basic CRUD scenarios.
*   ETS table interactions are asserted.
*   Error handling for common cases is tested.

---
#### Prompt 1.2.2: `Repository.Core` GenServer Structure and `init/1`

**Instruction to Gemini:**

"Generate the GenServer module `ElixirScope.AST.Repository.Core` in `lib/elixir_scope/ast/repository/core.ex`.

1.  **Module Definition:**
    *   `use GenServer`.
    *   `@moduledoc` explaining its role as the central ETS-based AST data store.
    *   Alias `ElixirScope.AST.Data.ModuleData`, `ElixirScope.AST.Data.FunctionData`, `ElixirScope.Foundation.Config`, `ElixirScope.Foundation.Error`, `ElixirScope.Foundation.Telemetry`.
2.  **Public API (`start_link/1`):**
    *   Implement `start_link(opts \\ [])`. It should call `GenServer.start_link(__MODULE__, opts, name: Keyword.get(opts, :name, __MODULE__))`. Add `@doc` and `@spec`.
3.  **GenServer Callbacks:**
    *   **`init/1`:**
        *   Accept `opts` (currently unused but allow for future config).
        *   Create the ETS tables: `:ast_modules`, `:ast_functions`, `:ast_nodes`, `:correlation_index`.
        *   Use options `[:set, :public, :named_table, {:read_concurrency, true}]` for `:ast_modules`, `:ast_functions`, `:ast_nodes`.
        *   Use options `[:bag, :public, :named_table, {:read_concurrency, true}]` for `:correlation_index`.
        *   (These options are from `docs/ast/EST_SCHEMA.md` Section 2 & 3, simplified for initial setup from `REQ-01`).
        *   Log an info message "AST Repository Core initialized."
        *   Return `{:ok, %{metrics: %{modules_stored: 0, functions_stored: 0, ...}}}` for initial state.
    *   **`terminate/2`:**
        *   Log an info message "AST Repository Core terminating."
        *   Delete the named ETS tables it created if they exist (e.g., `if :ets.whereis(:ast_modules) != :undefined, do: :ets.delete(:ast_modules)`).
        *   Return `:ok`.
    *   **Stubs for `handle_call/3`, `handle_cast/2`, `handle_info/2`:**
        *   Implement these callbacks to initially log an "unhandled message" warning and return `{:reply, :not_implemented, state}` or `{:noreply, state}`.

Add `@doc` and `@spec` for all public functions and GenServer callbacks.
"

**Success Metrics for Prompt 1.2.2:**
*   Module `ElixirScope.AST.Repository.Core` is generated.
*   Implements `GenServer` behaviour with `start_link/1`, `init/1`, `terminate/2`, and stubs for other callbacks.
*   `init/1` correctly creates the specified ETS tables with their respective options.
*   `terminate/2` attempts to clean up these ETS tables.
*   The module compiles without warnings.
*   The GenServer lifecycle tests from Prompt 1.2.1 should pass.

---
#### Prompt 1.2.3: Implement `Repository.Core` Module Storage/Retrieval

**Instruction to Gemini:**

"In `ElixirScope.AST.Repository.Core`:

1.  **Implement `handle_call({:store_module, module_data}, _from, state)`:**
    *   Validate that `module_data` is a `%ElixirScope.AST.Data.ModuleData{}` struct. If not, reply with `{:error, %Foundation.Error{type: :validation_failed, message: "Invalid ModuleData provided"}}`.
    *   Extract `module_data.module_name` as the key.
    *   Create the record to store in `:ast_modules` ETS table as `{module_key, module_data, compilation_hash, last_updated, access_count, memory_size}` (refer to `docs/ast/EST_SCHEMA.md` Section 2.1).
        *   For now, `compilation_hash` can be `module_data.compilation_hash`.
        *   `last_updated` = `DateTime.to_unix(module_data.updated_at, :nanosecond)`.
        *   `access_count` = `0`.
        *   `memory_size` = `:erlang.external_size(module_data)`.
    *   Insert into `:ast_modules` using `:ets.insert/2`.
    *   Update `state.metrics` for `modules_stored`.
    *   Reply with `{:ok, :stored}` (or a similar success atom).
    *   Emit a basic telemetry event `[:elixir_scope, :ast, :repository, :module_stored]` using `Foundation.Telemetry.execute/3` with measurements `%{count: 1}` and metadata `%{module_name: module_key}`.
2.  **Implement `handle_call({:get_module, module_name}, _from, state)`:**
    *   Perform an `:ets.lookup/2` on `:ast_modules` with `module_name`.
    *   If found (`[{^module_name, module_data_struct, _, _, _, _}]`):
        *   Reply with `{:ok, module_data_struct}`.
        *   (TODO for later prompt: Increment access_count asynchronously).
    *   If not found (`[]`):
        *   Reply with `{:error, %Foundation.Error{type: :not_found, message: "Module '#{module_name}' not found"}}`.
3.  **Implement `handle_call(:get_statistics, _from, state)`:**
    *   Return `{:ok, state.metrics}`.
4.  **Implement `handle_call(:health_check, _from, state)`:**
    *   Return `{:ok, %{status: :healthy, details: %{ets_tables_present: check_ets_tables_exist(), metrics: state.metrics}}}`.
    *   Create a private helper `check_ets_tables_exist/0` that verifies `:ast_modules`, etc., are defined.

Add necessary `@doc` and `@spec` annotations. Ensure error replies use `ElixirScope.Foundation.Error`.
"

**Success Metrics for Prompt 1.2.3:**
*   Module storage and retrieval logic implemented in `Repository.Core`.
*   Uses `Foundation.Error` for error replies.
*   Basic telemetry emitted for module storage.
*   `get_statistics` and a basic `health_check` are functional.
*   Module compiles.
*   Relevant tests from Prompt 1.2.1 for module operations, stats, and health check should now pass.

---

**(This detailed, iterative prompting would continue for `FunctionData` storage, other `Repository.Core` APIs, the `Repository.Supervisor`, and then move to other components in Phase 1, always generating tests first, then the module structure, then implementing features to make tests pass, and ensuring cross-cutting concerns are addressed.)**

---

## Phase 2: Parsing & Basic Queries

**Goal:** Implement the AST parsing engine, including AST enhancement for instrumentation, and a basic query system.
**Relevant Documents:** `docs/ast/REQ-02-PARSING-QUERIES.md`, `docs/ast/AST_PRD.md` (Sections 2.1.1, 2.4, 2.5), `docs/ast/MODULE_INTERFACES_DOCUMENTATION.md` (Sections 2, 4), `PLAN_AST_BLUEPRINT.md`, `PLAN_AST_TDD.md` (Phase 2), `PLAN_AST_CONCERNS.md`.

---
### Component: `ElixirScope.AST.Parser`

**File:** `lib/elixir_scope/ast/parser.ex`
**Role:** Module/GenServer for parsing Elixir source, enhancing AST, extracting instrumentation.
**References:** ... (similar to above)

#### Prompt 2.1.1: Test Generation for `Parser.parse_source/2` and Node ID Assignment

**Instruction to Gemini:**
"Generate tests in `test/unit/elixir_scope/ast/parser_test.exs` for `ElixirScope.AST.Parser`.

**Focus on `parse_source(source_input :: binary() | {binary(), binary()}, parse_config :: map()) :: {:ok, parse_result()} | {:error, Error.t()}` (interface from `MODULE_INTERFACES_DOCUMENTATION.md` Sec 2.1) and its ability to assign node IDs:**

1.  **Scenario: Basic `def` parsing & Node ID assignment:**
    *   **Arrange:** `source_input = "defmodule MyMod do def my_fun(a), do: a + 1 end"`, `parse_config = %{assign_node_ids: true, extract_instrumentation: false}`.
    *   **Act:** Call `Parser.parse_source(source_input, parse_config)`.
    *   **Assert:**
        *   Result is `{:ok, %{enhanced_ast: ast, ...}}`.
        *   The `ast` contains metadata.
        *   Traverse the `ast` to find the `def my_fun(a)` node. Assert it has a `meta[:ast_node_id]` which is a binary string.
        *   Assert the `defmodule MyMod` node also has an `ast_node_id`.
2.  **Scenario: Pipe operation node ID assignment:**
    *   **Arrange:** `source_input = "1 |> Kernel.+(2)"`, `parse_config = %{assign_node_ids: true}`.
    *   **Act:** Call `Parser.parse_source(source_input, parse_config)`.
    *   **Assert:** The pipe operator node (`{:|>, meta, [lhs, rhs]}`) in the `enhanced_ast` has `meta[:ast_node_id]`.
3.  **Scenario: `case` statement node ID assignment:**
    *   **Arrange:** `source_input = "case :foo do :bar -> :baz end"`, `parse_config = %{assign_node_ids: true}`.
    *   **Act:** Call `Parser.parse_source(source_input, parse_config)`.
    *   **Assert:** The `case` node and each clause (`->`) node in `enhanced_ast` have `meta[:ast_node_id]`.
4.  **Scenario: Syntax Error Handling:**
    *   **Arrange:** `source_input = "defmodule Invalid"`, `parse_config = %{}`.
    *   **Act:** Call `Parser.parse_source(source_input, parse_config)`.
    *   **Assert:** Result is `{:error, %Foundation.Error{type: :syntax_error, ...}}` containing details about the syntax error.
5.  **Scenario: `assign_node_ids: false`:**
    *   **Arrange:** `source_input = "defx my_other_fun, do: nil"`, `parse_config = %{assign_node_ids: false}`.
    *   **Act:** Call `Parser.parse_source(source_input, parse_config)`.
    *   **Assert:** Result is `{:ok, %{enhanced_ast: ast, ...}}`. Traverse the `ast`; nodes should *not* have `meta[:ast_node_id]`.

Use `Code.string_to_quoted!/2` or `Code.string_to_quoted/2` for AST generation in tests if needed for comparison.
Remember to include necessary aliases.
"
**Success Metrics for Prompt 2.1.1:** Test file generated, compiles, tests cover specified node ID assignment and error handling scenarios.

---

**(The prompts would continue in this fashion, covering all components and functionalities for all 5 phases, always generating tests first, then module/function shells, then implementations, and ensuring concerns are addressed throughout. Each prompt block would have its own detailed success metrics for Gemini's output.)**

---
## Concluding Section (Overall Validation Strategy - Example Snippet)

Once all phases are complete, the following overall validation will be performed:

1.  **Full Regression Suite:** Execute all generated unit, integration, and contract tests.
    *   **Success Metric:** 100% test pass rate.
2.  **End-to-End Workflow Tests (as per `DEV.md` and `AST_PRD.md` data flow):**
    *   Prompt for tests covering: Source Code -> `Parser` -> `Repository` -> `PatternMatcher` -> Query via `QueryBuilder`/`Executor`.
    *   Prompt for tests covering: File Change -> `FileWatcher` -> `Synchronizer` -> `IncrementalUpdater` -> `Repository` -> Updated Query Result.
    *   **Success Metric:** Key end-to-end workflows function correctly and data remains consistent.
3.  **Performance Benchmarking (as per `AST_PRD.md` Section 5):**
    *   Prompt for benchmark scripts (e.g., using Benchee) for critical operations:
        *   Parsing N modules.
        *   Executing common query types against M records.
        *   Pattern matching K patterns against P functions.
        *   Incremental sync latency.
    *   **Success Metric:** Performance targets from `AST_PRD.md` are met.
4.  **Memory Profiling:**
    *   Prompt for scenarios to analyze memory usage under load (e.g., parsing a large project, sustained querying).
    *   Verify AST local memory management and coordination with Foundation MemoryManager.
    *   **Success Metric:** Memory usage stays within `AST_PRD.md` limits (e.g., <2GB for large projects), and pressure handling works as expected.
5.  **Dialyzer Analysis:**
    *   Run Dialyzer on the entire AST layer.
    *   **Success Metric:** Zero Dialyzer errors (or only agreed-upon, documented ignores).
6.  **Documentation Review:**
    *   Verify `@moduledoc`, `@doc`, `@spec` are comprehensive and accurate.
    *   **Success Metric:** Code is well-documented.

This meticulous, staged, and test-driven approach, guided by these detailed prompts, aims to produce a high-quality, robust, and well-verified ElixirScope AST Layer.
```

This is the beginning of `PROMPTS_GEMINI.MD`. As you can see, it's already quite extensive for just the introduction and the first component of the first phase. Generating the complete file according to the plan would be a very large output, likely exceeding typical response limits many times over.

**To proceed, I would continue generating prompts for:**
*   The rest of Phase 1 components (`FunctionData`, `Repository.Supervisor`, other `Repository.Core` functions).
*   Then Phase 2 components (`Parser` implementation, `InstrumentationMapper`, `QueryBuilder`, `QueryExecutor`, etc.).
*   And so on for Phases 3, 4, and 5.

Each prompt would be crafted with similar detail, referencing the relevant planning documents and source design files, always asking for tests first, then the skeletal code structure, then the implementation details feature by feature, and finally integration/refinement.